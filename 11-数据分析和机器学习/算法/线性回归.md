### 线性回归



满秩矩阵

- ### 矩阵内部进行四则运算时后，行数和列数还是相同的
- 满秩矩阵求解释最精确的

奇异矩阵

- 该矩阵不是满秩的，线性代数的概念
- 奇异矩阵可以通过岭回归求解



判断满秩矩阵

- `np.linalg.martrix_rank(ndarry)` 查看矩阵的秩，和数组的 shape 进行对比



矩阵的逆

- 矩阵本身和自身的逆矩阵相乘得到的是单位矩阵

![1531802202472](assets/1531802202472.png)



求矩阵的的逆矩阵

`n_T = np.linalg.inv(ndarray)`



### 岭回归

- 最小二乘法

岭回归是加了二阶正则项的最小二乘， 主要是用于过拟合严重和存在多重共线性，岭回归室友 bias 的，这里的 bias 是为了 vanance 更小

- 过拟合严重： x + y = 1  2x + 2y = 2
- 多重共线： 两个正相关的属性，同时对结果进行求解
- bias ：偏差
- vanance：

一般用于样本值不够的时候

![1531810473351](assets/1531810473351.png)

#### 参数

```python

from sklearn.linear_model import Ridge

ridge = Ridge(alpha=1.0)  # alpha 表示的是：当维度不够时给予的补充单位矩阵
```



### lasso 回归

- 使用的是拉格朗日乘法

对参数 w 增加了限定条件， 可以达到岭回归相同的结果





### 逻辑斯蒂回归  Logistic

更具数据对分类的边界线建立回归公式，

目的主要是用于分类

**梯度下降算法**



优缺点：

- 优点：实现简单，易于理解和实现，计算代价不高，速度快，存储资源低
- 缺点：容易欠拟合，分类的精度可能不高

`from sklearn.linear_model import LogaisticRegression`

以回归的算法实现数据的分类

c ：正则化，c 越大， 正则化越小



### make_blobs 产生数据集



`from sklearn.datasets import make_blobs`



make_blobs()

- n_samples 样本数
- n_features  特征数
- centers  中心点  `[[0, 0],[-2, -2],[3, 2]]`

